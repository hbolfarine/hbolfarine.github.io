[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Henrique Bolfarine",
    "section": "",
    "text": "Henrique Bolfarine is a lecturer at the University of Texas at Austin. Change - another change 256"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Henrique Bolfarine",
    "section": "Education",
    "text": "Education\nUniversidade de São Paulo (USP), São Paulo\nPhD in Statistics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Henrique Bolfarine",
    "section": "",
    "text": "Henrique Bolfarine is a lecturer at the University of Texas at Austin. Change - another change 256"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "STA 235 honors change 25\n\nclass 01 - Simple and Multiple Regression\nclass 02 - Categorical Variables and Interactions\nclass 03 - Regression assumptions and Outliers"
  },
  {
    "objectID": "teaching.html#teaching",
    "href": "teaching.html#teaching",
    "title": "Teaching",
    "section": "",
    "text": "Modifcation"
  },
  {
    "objectID": "class_01.html#what-is-data-science",
    "href": "class_01.html#what-is-data-science",
    "title": "Data Science for Business Applications",
    "section": "What is Data Science?",
    "text": "What is Data Science?\n\nIn Data Science we use the available data to obtain:"
  },
  {
    "objectID": "class_01.html#data-science-tasks",
    "href": "class_01.html#data-science-tasks",
    "title": "Data Science for Business Applications",
    "section": "Data Science tasks",
    "text": "Data Science tasks\n\nDescription: Can we classify our customers into different segments? (simple task)\nPrediction: What is the probability of a shopper coming back to our website? (kind of a simple task)\nCausal Inference: What is the effect of increasing our advertising budget on our total revenue? (difficult task)"
  },
  {
    "objectID": "class_01.html#simple-and-multiple-regression",
    "href": "class_01.html#simple-and-multiple-regression",
    "title": "Data Science for Business Applications",
    "section": "Simple and Multiple Regression",
    "text": "Simple and Multiple Regression\n\nLinear Regression will be the most important tool for solving these Data Science tasks.\nBasically, in the linear regression model, we are explaining the relation between different variables by a line (that’s where the linear comes from.)\nMany fancy methods are generalizations or extensions of Linear Regression!\nIn this class, we will do a quick review on linear regression."
  },
  {
    "objectID": "class_01.html#cookie-example",
    "href": "class_01.html#cookie-example",
    "title": "Data Science for Business Applications",
    "section": "Cookie Example",
    "text": "Cookie Example\n\n\n\nSuppose we have some data, and we want to understand how happiness changes in relation to the number of cookies eaten.\nTo do so, we summarize the relation between these two variables through a line.\nThis line is the linear regression line.\nLet’s see how this works!\n\n\n\n\n\ncookies\nhappiness\n\n\n\n\n1\n0.1\n\n\n2\n2\n\n\n3\n1\n\n\n4\n2.5\n\n\n5\n3\n\n\n6\n1.3\n\n\n7\n1.9\n\n\n8\n2.4\n\n\n9\n1.8\n\n\n10\n3"
  },
  {
    "objectID": "class_01.html#cookie-example-1",
    "href": "class_01.html#cookie-example-1",
    "title": "Data Science for Business Applications",
    "section": "Cookie Example",
    "text": "Cookie Example\n\n\n\nThe regression line is defined by two values, the intercept and the slope.\nThe intercept is where the line intercepts the happiness axis.\nThe slope relates to the inclination of the line.\nIf the slope is positive the line has a upward direction.\nIf the slope is negative the line has a downward direction.\nThe regression line is a model of the relation between happiness and the number of cookies eaten."
  },
  {
    "objectID": "class_01.html#some-questions-on-regression",
    "href": "class_01.html#some-questions-on-regression",
    "title": "Data Science for Business Applications",
    "section": "Some questions on regression",
    "text": "Some questions on regression\n\nFrom the regression line, what is the relationship between happiness and the number of cookies eaten?\nAre there other factors other than the number of cookies that might affect the happiness level?\nFrom this model, can we conclude that eating cookies alone causes happiness?\nWhy not look only at the correlation between happiness and the number of cookies?\nHow do we obtain the intercept and the slope?\nDoes this result apply to the entire population?"
  },
  {
    "objectID": "class_01.html#regressions-details",
    "href": "class_01.html#regressions-details",
    "title": "Data Science for Business Applications",
    "section": "Regressions Details",
    "text": "Regressions Details\n\nThe Linear Regression model is represented by the formula: \\[\nY = \\beta_0 + \\beta_1\\cdot X_1 + \\beta_2\\cdot X_2 + e\n\\]\nMultiple Regression means we have two or more \\(X\\)’s.\nLet’s break down this model into its essential parts."
  },
  {
    "objectID": "class_01.html#essential-parts-of-a-regression",
    "href": "class_01.html#essential-parts-of-a-regression",
    "title": "Data Science for Business Applications",
    "section": "Essential Parts of a Regression",
    "text": "Essential Parts of a Regression\n\n\\(Y\\) - Outcome Variable, Response Variable, Dependent Variable (Thing you want to explain or predict)\n\\(X\\) - Explanatory Variable, Predictor Variable, Independent Variable, Covariate (Thing you use to explain or predict \\(Y\\))\n\\(\\beta\\)’s - Coefficients, Parameters (How \\(Y\\) changes numerically in relation to \\(X\\))\n\\(e\\) - Residual, Noise (Things we didn’t account in our model)"
  },
  {
    "objectID": "class_01.html#two-purposes-of-regression",
    "href": "class_01.html#two-purposes-of-regression",
    "title": "Data Science for Business Applications",
    "section": "Two Purposes of Regression",
    "text": "Two Purposes of Regression"
  },
  {
    "objectID": "class_01.html#back-to-the-cookie-example",
    "href": "class_01.html#back-to-the-cookie-example",
    "title": "Data Science for Business Applications",
    "section": "Back to the Cookie example",
    "text": "Back to the Cookie example\n\nBy writing the cookie example as a model where the variable happiness is the response variable and the number of cookies is the predictor, we have \\[\n\\texttt{happiness} = \\beta_0 + \\beta_1\\cdot\\texttt{cookies} + e\n\\]\nhappiness is the response variable (\\(Y\\)).\ncookies is the predictor variable (\\(X\\)).\n\\(\\beta_0\\) is the intercept.\n\\(\\beta_1\\) is the slope associate to the cookies variable.\n\\(e\\) are the unknown factors that might explain the relation between cookies and happiness.\nThe challenge now is to estimate the parameters \\(\\beta_0\\), and \\(\\beta_1\\)."
  },
  {
    "objectID": "class_01.html#how-do-we-estimate-the-coefficients-in-a-regression",
    "href": "class_01.html#how-do-we-estimate-the-coefficients-in-a-regression",
    "title": "Data Science for Business Applications",
    "section": "How do we estimate the coefficients in a regression?",
    "text": "How do we estimate the coefficients in a regression?\n\nA very useful strategy is use what is called the Ordinary Least Squares (OLS).\nThe method is called ordinary least squares because the algorithm selects the coefficients (\\(\\beta\\)’s) that minimize the sum of the squares of the errors in our sample.\nSo the data in this case is fundamental.\nWe use R to learn \\(\\beta\\).\nThe estimated coefficients are referred to as \\(\\widehat{\\beta}\\)."
  },
  {
    "objectID": "class_01.html#lets-get-into-some-data",
    "href": "class_01.html#lets-get-into-some-data",
    "title": "Data Science for Business Applications",
    "section": "Let’s get into some data",
    "text": "Let’s get into some data\n\nExample: Movie data Set (movie_1990_data.csv)\nWe will create a model that explains and predicts the movie revenue in terms of the budget.\nThere are 1,368 different movies in the data, with 22 different attributes.\nThis means that the data contains 1,368 lines and 22 columns.\nWe are interested in two attributes, the movie budget, and movie revenue.\nMovie budget is in the predictor variable - Adj_Budget.\nMovie revenue is in the response variable - Adj_Revenue.\nThe units in this case are important (both are in millions of dollars).\nLet’s visualize the relation between these two variables."
  },
  {
    "objectID": "class_01.html#section",
    "href": "class_01.html#section",
    "title": "Data Science for Business Applications",
    "section": "",
    "text": "First we load the library tidyverse, then we use the ggplot function to make plot between Adj_Budget and Adj_Revenue\n\n\n# Load library\nlibrary(tidyverse)\n\n# Create plot\nggplot(movie_1990_data) +\n  geom_point(aes(x = Adj_Budget, y = Adj_Revenue))"
  },
  {
    "objectID": "class_01.html#section-1",
    "href": "class_01.html#section-1",
    "title": "Data Science for Business Applications",
    "section": "",
    "text": "We encode the model below in R.\n\\[\n\\texttt{Adj_Revenue} = \\beta_0 + \\beta_1\\cdot\\texttt{Adj_Budget} + e\n\\]\n\n# The model\n# Revenue = intercept + slope*Budget + e\nlm1 &lt;- lm(Adj_Revenue ~ Adj_Budget, data = movie_1990_data)\nsummary(lm1)\n\n\nCall:\nlm(formula = Adj_Revenue ~ Adj_Budget, data = movie_1990_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-262.40  -38.01  -16.39   19.24  619.23 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 22.66095    3.15001   7.194 1.03e-12 ***\nAdj_Budget   1.11043    0.03738  29.709  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 79.78 on 1366 degrees of freedom\nMultiple R-squared:  0.3925,    Adjusted R-squared:  0.3921 \nF-statistic: 882.6 on 1 and 1366 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "class_01.html#lets-interpret-the-output",
    "href": "class_01.html#lets-interpret-the-output",
    "title": "Data Science for Business Applications",
    "section": "Let’s interpret the output",
    "text": "Let’s interpret the output\n\nFrom the coefficients, \\(\\widehat\\beta_0 = 22.7\\), \\(\\widehat\\beta_1 = 1.11\\) we have the updated model: \\[\n\\widehat{\\texttt{Adj_Revenue}} = 22.7 + 1.11\\cdot\\texttt{Adj_Budget}\n\\]\nWhen there’s a hat, it means that the values were generated from the data.\n\\(e\\) (noise) vanishes because we eliminated the unknown factors and concentrated the effect on what we observe.\nNow we have the residuals, that is the distance between the points in the data and the regression model.\nThe question now is: how can we interpret this result?"
  },
  {
    "objectID": "class_01.html#explanation",
    "href": "class_01.html#explanation",
    "title": "Data Science for Business Applications",
    "section": "Explanation",
    "text": "Explanation\n\nIntercept: By setting the movie budget to zero, we have that the average revenue is equal to $22.7 million dollars.\nSlope: For one unit change in the movie budget, that is, millions, there will be an increase of $1.11 million dollars in the movie’s revenue."
  },
  {
    "objectID": "class_01.html#section-2",
    "href": "class_01.html#section-2",
    "title": "Data Science for Business Applications",
    "section": "",
    "text": "Let’s visualize this model.\n\n# Create plot with regression line\nggplot(movie_1990_data) +\n  geom_point(aes(x = Adj_Budget, y = Adj_Revenue)) +\n  geom_smooth(aes(x = Adj_Budget, y = Adj_Revenue), method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "class_01.html#statistical-significance-of-the-model",
    "href": "class_01.html#statistical-significance-of-the-model",
    "title": "Data Science for Business Applications",
    "section": "Statistical significance of the model",
    "text": "Statistical significance of the model\n\nAre these coefficients statistically significant?\nCan we extrapolate the results to the larger population?\nWe can answer these questions by looking at the confidence interval (CI).\n\n\n# We use the confint() function to get the confidence interval\nconfint(lm1)\n\n                2.5 %    97.5 %\n(Intercept) 16.481572 28.840332\nAdj_Budget   1.037112  1.183756"
  },
  {
    "objectID": "class_01.html#statistical-significance-of-the-model-1",
    "href": "class_01.html#statistical-significance-of-the-model-1",
    "title": "Data Science for Business Applications",
    "section": "Statistical significance of the model",
    "text": "Statistical significance of the model\nFrom the confidence interval we have that:\n\n\n\nThe value of the intercept is statistically different from zero since zero is not between the lower and upper values of the interval .\nThe value of the slope is statistically different from zero since zero is not between the lower and upper values of the interval .\n\n\n\nWith 95% confidence, the value of the intercept at the population level is between 16.5 and 28.8 million dollars .\nWith 95% confidence, the value of the slope at the population level is between 1.04 and 28.8 million dollars ."
  },
  {
    "objectID": "class_01.html#predictions",
    "href": "class_01.html#predictions",
    "title": "Data Science for Business Applications",
    "section": "Predictions",
    "text": "Predictions\n\nSuppose we want to predict the revenue of a movie , knowing that the revenue was $25 million.\nWe can use our estimated model to make the prediction.\nInput the value into the adjusted budget, resulting in: \\[\n\\widehat{\\texttt{Adj_Revenue}} = 22.7 + 1.11\\cdot 25 = 50.45\n\\]\nThe average predicted revenue of a $25 million dollar budget movie is $50 million dollars.\nWe can also do this using the predict function in R\n\n\n# We use the predict() function to get predictions\npredict(lm1, list(Adj_Budget = 25))\n\n       1 \n50.42179"
  },
  {
    "objectID": "class_01.html#predictions-1",
    "href": "class_01.html#predictions-1",
    "title": "Data Science for Business Applications",
    "section": "Predictions",
    "text": "Predictions\n\nHow good are these predictions?\nWe can use the residual standard error (RSE), which is a result of the summary function.\n\\(\\texttt{Residual standard error: 79.78}\\),\nThese mean that our predictions will be off by approximately 79.78.\nWith 95% confidence, the prediction of the revenue will be 50.42 plus and minus \\(2\\times 79.78 = 159.56\\).\nQuite a big variation."
  },
  {
    "objectID": "class_01.html#adding-more-variables",
    "href": "class_01.html#adding-more-variables",
    "title": "Data Science for Business Applications",
    "section": "Adding more variables",
    "text": "Adding more variables\n\nWe can add more variables in our model.\nWe will add the variable imdbRating which encodes the different IMDB ratings in the data (1-10).\nThe resulting model now is \\[\n\\texttt{Adj_Revenue} = \\beta_0 + \\beta_1\\cdot\\texttt{Adj_Budget} + \\beta_2\\cdot\\texttt{imdbRating} + e\n\\]\nYou can observe that we have an extra slope in the equation.\nThis will have an impact in how we interpret the model.\nNext we encode this model in R"
  },
  {
    "objectID": "class_01.html#explore-the-data-beauty",
    "href": "class_01.html#explore-the-data-beauty",
    "title": "Data Science for Business Applications",
    "section": "Explore the data: beauty",
    "text": "Explore the data: beauty"
  },
  {
    "objectID": "class_01.html#relation-bewteen-variables",
    "href": "class_01.html#relation-bewteen-variables",
    "title": "Data Science for Business Applications",
    "section": "Relation bewteen variables",
    "text": "Relation bewteen variables\n\n\nLet’s interpret the model:\n\n\n\\[\n\\texttt{Adj_Revenue} = -136.507 + 1.091 \\cdot\\texttt{Adj_Budget} + 24.099\\cdot\\texttt{imdbRating}\n\\]"
  },
  {
    "objectID": "class_01.html#correlation",
    "href": "class_01.html#correlation",
    "title": "Data Science for Business Applications",
    "section": "Correlation",
    "text": "Correlation\n\nRegressions are super useful…\nBut you need to know how to interpret them.\nBe sure not to overstate your claims!\nRemember the magic words for interpretation"
  },
  {
    "objectID": "class_01.html#correlation-1",
    "href": "class_01.html#correlation-1",
    "title": "Data Science for Business Applications",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "class_01.html#correlation-between-variables",
    "href": "class_01.html#correlation-between-variables",
    "title": "Data Science for Business Applications",
    "section": "Correlation between variables",
    "text": "Correlation between variables\n\nLet’s calculate the correlation between evaluation and beauty\n\n\ncor(profs$eval, profs$beauty)\n\n[1] 0.1890391\n\n\n\nHow can we interpret this?\nInstead of trying to interpret the correlation, we can build a model that reveals the relationship between the professor’s evaluation and their beauty score."
  },
  {
    "objectID": "class_01.html#simple-regression-model",
    "href": "class_01.html#simple-regression-model",
    "title": "Data Science for Business Applications",
    "section": "Simple regression model",
    "text": "Simple regression model\n\nmodel &lt;- lm(eval ~ beauty, data=profs)\nsummary(model)\n\n\nCall:\nlm(formula = eval ~ beauty, data = profs)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.80015 -0.36304  0.07254  0.40207  1.10373 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.99827    0.02535 157.727  &lt; 2e-16 ***\nbeauty       0.13300    0.03218   4.133 4.25e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5455 on 461 degrees of freedom\nMultiple R-squared:  0.03574,   Adjusted R-squared:  0.03364 \nF-statistic: 17.08 on 1 and 461 DF,  p-value: 4.247e-05"
  },
  {
    "objectID": "class_01.html#interpreting-the-model",
    "href": "class_01.html#interpreting-the-model",
    "title": "Data Science for Business Applications",
    "section": "Interpreting the model",
    "text": "Interpreting the model\n\neval is the response variable (\\(Y\\));\nbeauty is the predicton variable (\\(X\\))\nSimple regression uses the best fit line to give us a linear equation to predict \\(Y\\) from \\(X\\):\n\n\\[\n\\text{eval} = 3.998 + 0.133\\cdot \\text{beauty}\n\\]\n\nWe can predict the evaluation score for someone based on their beauty score just by plugging into the equation.\nWhat do the coefficients mean?"
  },
  {
    "objectID": "class_01.html#interpreting-the-model-1",
    "href": "class_01.html#interpreting-the-model-1",
    "title": "Data Science for Business Applications",
    "section": "Interpreting the model",
    "text": "Interpreting the model"
  },
  {
    "objectID": "class_01.html#interpreting-the-model-2",
    "href": "class_01.html#interpreting-the-model-2",
    "title": "Data Science for Business Applications",
    "section": "Interpreting the model",
    "text": "Interpreting the model\n\nWe can predict the evaluation score for someone based on their beauty score just by plugging into the equation.\nWhat do the coefficients mean?\nBut what does the population that it was drawn from look like?"
  },
  {
    "objectID": "class_01.html#statistical-significance-of-the-model-2",
    "href": "class_01.html#statistical-significance-of-the-model-2",
    "title": "Data Science for Business Applications",
    "section": "Statistical significance of the model",
    "text": "Statistical significance of the model\n\nLet’s analyse the confidence interval\n\n\n# We use the confint() function to get the confidence interval\nconfint(lm2)\n\n                  2.5 %      97.5 %\n(Intercept) -165.245169 -107.768758\nAdj_Budget     1.020706    1.161364\nimdbRating    19.841475   28.357234\n\n\n\nAll coefficients are statistically significant."
  },
  {
    "objectID": "class_01.html#statistical-significance-of-the-model-3",
    "href": "class_01.html#statistical-significance-of-the-model-3",
    "title": "Data Science for Business Applications",
    "section": "Statistical significance of the model",
    "text": "Statistical significance of the model\n\nThe population regression line (the best fit line in the population) is \\[Y = \\beta_0 + \\beta_1 X + \\text{noise}\\]\nUsually we don’t have access to the entire population, so we can’t know this\nThe noise term represents what we haven’t accounted for in our model"
  },
  {
    "objectID": "class_01.html#statistical-significance-of-the-model-4",
    "href": "class_01.html#statistical-significance-of-the-model-4",
    "title": "Data Science for Business Applications",
    "section": "Statistical significance of the model",
    "text": "Statistical significance of the model\n\nOur regression equation is the best fit line in the sample, or \\[\\widehat{Y} = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 X\\]\nThis is what we get from our sample data\nThe sample intercept and slope \\(\\widehat\\beta_0\\) and \\(\\widehat\\beta_1\\)\nare our best estimates for the population intercept\nand slope \\(\\beta_0\\) and \\(\\beta_1\\)\nBut we need to get a sense of how close \\(\\widehat\\beta_0\\) and \\(\\widehat\\beta_1\\) are to \\(\\beta_0\\) and \\(\\beta_1\\)!"
  },
  {
    "objectID": "class_01.html#confidence-intervals",
    "href": "class_01.html#confidence-intervals",
    "title": "Data Science for Business Applications",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\nLet’s form confidence intervals for the slope and intercept to get a sense of the uncertainty in our estimates:\n\n\nconfint(model)\n\n                 2.5 %    97.5 %\n(Intercept) 3.94845765 4.0480866\nbeauty      0.06976869 0.1962342"
  },
  {
    "objectID": "class_01.html#confidence-intervals-1",
    "href": "class_01.html#confidence-intervals-1",
    "title": "Data Science for Business Applications",
    "section": "Confidence intervals",
    "text": "Confidence intervals\n\n\\(\\beta_1\\): We are 95% confident that the incremental impact of each additional beauty point is between \\(0.07\\) and \\(0.20\\) student evaluation points.\n\\(\\beta_0\\): We are 95% confident that the average student evaluation score for average-looking professors (beauty = 0) is between \\(3.95\\) and \\(4.05\\)"
  },
  {
    "objectID": "class_01.html#confidence-intervals-for-predictions",
    "href": "class_01.html#confidence-intervals-for-predictions",
    "title": "Data Science for Business Applications",
    "section": "Confidence intervals for predictions",
    "text": "Confidence intervals for predictions\n\nConfidence for a given prediction\n\n\npredict(model, list(beauty=1), interval=\"prediction\")\n\n       fit      lwr      upr\n1 4.131274 3.056375 5.206172\n\n\n\nWe are 95% confident that a single professor with a beauty score of 1 will get rated between 3.06 and 5.21."
  },
  {
    "objectID": "class_01.html#confidence-intervals-for-predictions-1",
    "href": "class_01.html#confidence-intervals-for-predictions-1",
    "title": "Data Science for Business Applications",
    "section": "Confidence intervals for predictions",
    "text": "Confidence intervals for predictions\n\nConfidence for the average prediction\n\n\npredict(model, list(beauty=1), interval=\"confidence\")\n\n       fit      lwr      upr\n1 4.131274 4.050776 4.211771\n\n\n\nWe are 95% confident that the will be between\n4.05 and 4.21"
  },
  {
    "objectID": "class_01.html#residuals",
    "href": "class_01.html#residuals",
    "title": "Data Science for Business Applications",
    "section": "Residuals",
    "text": "Residuals\n\nEach instructor has a residual: the difference between their actual and predicted scores (the prediction error)."
  },
  {
    "objectID": "class_01.html#residuals-1",
    "href": "class_01.html#residuals-1",
    "title": "Data Science for Business Applications",
    "section": "Residuals",
    "text": "Residuals\n\nThis instructor has a positive residual—their evaluation score was higher than expected given their beauty:"
  },
  {
    "objectID": "class_01.html#residuals-2",
    "href": "class_01.html#residuals-2",
    "title": "Data Science for Business Applications",
    "section": "Residuals",
    "text": "Residuals\n\nThis instructor has a negative residual—their evaluation score was lower than expected given their beauty:"
  },
  {
    "objectID": "class_01.html#residuals-3",
    "href": "class_01.html#residuals-3",
    "title": "Data Science for Business Applications",
    "section": "Residuals",
    "text": "Residuals\n\nThe residuals are approximately Normally distributed with a mean of 0:"
  },
  {
    "objectID": "class_01.html#practical-significance-of-the-model",
    "href": "class_01.html#practical-significance-of-the-model",
    "title": "Data Science for Business Applications",
    "section": "Practical significance of the model",
    "text": "Practical significance of the model\n\nWe know that there is a statistically significant relationship between beauty and eval, so we can be highly confident they are indeed related in the larger population. But it that relationship meaningful?\nThe of \\(0.545\\) tells us that the standard deviation of the residuals is about \\(0.545\\) points"
  },
  {
    "objectID": "class_01.html#practical-significance-of-the-model-1",
    "href": "class_01.html#practical-significance-of-the-model-1",
    "title": "Data Science for Business Applications",
    "section": "Practical significance of the model",
    "text": "Practical significance of the model\n\nThat means that 95% of the residuals are less than \\(2\\cdot 0.545=1.09\\) (since 95% of a Normal distribution is within \\(\\pm 2\\) SD of the mean)\nIn other words, 95% of the time when using beauty to predict evaluation scores, we’ll be off by\nless than 1.09 point"
  },
  {
    "objectID": "class_01.html#practical-significance-of-the-model-2",
    "href": "class_01.html#practical-significance-of-the-model-2",
    "title": "Data Science for Business Applications",
    "section": "Practical significance of the model",
    "text": "Practical significance of the model\n\nThe \\(R^2\\) of \\(0.0357\\) tells us that about 4% of the variation between professors in student evaluations can be explained by their beauty\nLook at the difference in \\(\\widehat{\\text{eval}}\\) between someone super-hot (beauty = 2) and super-not (beauty = \\(-1.5\\)); the difference in their predicted student evaluations is \\(3.5 \\cdot 0.133 = 0.466\\)\nWe have to use our subjective judgment to decide whether these indicate a meaningful (practically significant) relationship"
  },
  {
    "objectID": "class_01.html#adding-more-variables-1",
    "href": "class_01.html#adding-more-variables-1",
    "title": "Data Science for Business Applications",
    "section": "Adding more variables",
    "text": "Adding more variables\n\n# The model\n# Revenue = intercept + slope*Budget + slope*Rating + e\nlm2 &lt;- lm(Adj_Revenue ~ Adj_Budget + imdbRating, data = movie_1990_data)\nsummary(lm2)\n\n\nCall:\nlm(formula = Adj_Revenue ~ Adj_Budget + imdbRating, data = movie_1990_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-256.79  -41.25  -14.97   26.55  598.53 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -136.50696   14.64962  -9.318   &lt;2e-16 ***\nAdj_Budget     1.09103    0.03585  30.433   &lt;2e-16 ***\nimdbRating    24.09935    2.17050  11.103   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 76.43 on 1365 degrees of freedom\nMultiple R-squared:  0.4428,    Adjusted R-squared:  0.442 \nF-statistic: 542.5 on 2 and 1365 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "class_01.html#visualizing-the-model",
    "href": "class_01.html#visualizing-the-model",
    "title": "Data Science for Business Applications",
    "section": "Visualizing the model",
    "text": "Visualizing the model"
  },
  {
    "objectID": "class_01.html#explanation-1",
    "href": "class_01.html#explanation-1",
    "title": "Data Science for Business Applications",
    "section": "Explanation",
    "text": "Explanation\n\n\nLet’s interpret the model:\n\n\n\\[\n\\texttt{Adj_Revenue} = -136.507 + 1.091 \\cdot\\texttt{Adj_Budget} + 24.099\\cdot\\texttt{imdbRating}\n\\]\n\nIntercept: By setting the movie budget and the rating to zero, we have that the average revenue is equal to $-137 million dollars.\nSlope Budget: For movies with the same fixed rating, for one unit change in the movie budget, there will be an increase of $1.091 million dollars in the movie’s revenue.\nSlope Rating: For movies with the same fixed budget, for one unit change in the movie rating, there will be an increase of $24.1 million dollars in the movie’s revenue."
  },
  {
    "objectID": "class_01.html#what-about-the-predictions",
    "href": "class_01.html#what-about-the-predictions",
    "title": "Data Science for Business Applications",
    "section": "What about the predictions?",
    "text": "What about the predictions?\n\nWe can observe from the summary that the residual standard error when down to \\(\\texttt{76.43}\\).\nWhich will result in more accurate predictions.\nSuppose we have a movie 25 million dollar budget and the movie has a IMDb rating of 5.4 what is the prediction for this movie?\nWhat about the 95% prediction interval for this prediction?\n\n\n# We use the confint() function to get the confidence interval\npredict(lm2, list(Adj_Budget = 25, imdbRating = 5.4))\n\n       1 \n20.90542 \n\n\n\nWhat about the 95% prediction interval for this prediction?\nupper bound: \\(20.90542 + 2\\times 76.43 = 173.7654\\)\nlower bound: \\(20.90542 - 2\\times 76.43 = -131.9546\\)"
  },
  {
    "objectID": "class_01.html#whats-next",
    "href": "class_01.html#whats-next",
    "title": "Data Science for Business Applications",
    "section": "What’s next?",
    "text": "What’s next?\n\nWe’ll include categorical variables.\nInteractions between categorical and numerical variables."
  },
  {
    "objectID": "class_02.html",
    "href": "class_02.html",
    "title": "Data Science for Business Applications",
    "section": "",
    "text": "Recall what are the goals of the linear regression model"
  },
  {
    "objectID": "class_02.html#regresison-model-goals",
    "href": "class_02.html#regresison-model-goals",
    "title": "Data Science for Business Applications",
    "section": "Regresison model goals",
    "text": "Regresison model goals\n\n\nRecall what are the goals of the linear regression model"
  },
  {
    "objectID": "class_02.html#data-science-tasks",
    "href": "class_02.html#data-science-tasks",
    "title": "Data Science for Business Applications",
    "section": "Data Science tasks",
    "text": "Data Science tasks\n\nWe found that adding more predictors to linear models increases their accuracy and explanatory power.\nWhat if we want to add instead of Quantative predictors, Qualitative predictors?\nCategorical or Qualitative Variables split the data into different groups or levels.\nHow can we add these types of variables in the regression model?"
  },
  {
    "objectID": "class_02.html#lets-start-with-an-example",
    "href": "class_02.html#lets-start-with-an-example",
    "title": "Data Science for Business Applications",
    "section": "Let’s start with an example!",
    "text": "Let’s start with an example!\n\n\nExample: Cars dataset (cars_luxury.csv)\nData on 2,088 used cars in South California\nFor each car there are several predictors as:\nprice: Price of the car in dollars.\nmileage: Car mileage.\nluxury: If the car is a luxury car: “\\(\\texttt{yes}\\)”or “\\(\\texttt{no}\\)”\nbadge: Badge indicating if the car is considered some type of deal, that can be: “\\(\\texttt{Good Deal}\\)”, “\\(\\texttt{Great Deal}\\)”, “\\(\\texttt{No Badge}\\)” or “\\(\\texttt{Fair Price}\\)”.\n(and others)"
  },
  {
    "objectID": "class_02.html#luxury-and-price",
    "href": "class_02.html#luxury-and-price",
    "title": "Data Science for Business Applications",
    "section": "Luxury and price",
    "text": "Luxury and price\n\n\nBefore we start our analysis, let’s see if there’s a difference between the used price of luxury and not luxury cars.\n\n\n\n\nlibrary(tidyverse)\nggplot(cars_luxury, aes(x = luxury, y = price)) +\n  geom_boxplot()"
  },
  {
    "objectID": "class_02.html#regression-model",
    "href": "class_02.html#regression-model",
    "title": "Data Science for Business Applications",
    "section": "Regression model",
    "text": "Regression model\n\nIt’s interesting to incorporate the categorical variable luxury, into the multiple regression model.\nWe want to see the impact of mileage on price controlling for the type of car. If it’s a luxury or not.\nThe resulting model is equal to: \\[\n\\texttt{price} = \\beta_0 + \\beta_1\\texttt{mileage} + \\beta_2\\texttt{luxury} + e\n\\]\nHow can we assess the categorical variable luxury?"
  },
  {
    "objectID": "class_02.html#price-in-terms-of-mileage-and-luxury",
    "href": "class_02.html#price-in-terms-of-mileage-and-luxury",
    "title": "Data Science for Business Applications",
    "section": "Price in terms of mileage and luxury",
    "text": "Price in terms of mileage and luxury\n\n\nLet’s plot the relation between mileage, price and luxury\n\n\n\nggplot(cars_luxury, aes(x = mileage, y = price, col = luxury)) +\n  geom_point()"
  },
  {
    "objectID": "class_02.html#dummy-variable",
    "href": "class_02.html#dummy-variable",
    "title": "Data Science for Business Applications",
    "section": "Dummy variable",
    "text": "Dummy variable\n\nluxury is a categorical variable (\\(\\texttt{\"yes\"}\\) or \\(\\texttt{\"no\"}\\) in this data set).\nThis variable contains two groups or two levels.\nRecode luxury into a quantitative variable where \\(\\texttt{1 = \"yes\"}\\), \\(\\texttt{0 = \"no\"}\\).\nThis quantitative variable is known as dummy variable.\nR does this for us.\nR will choose the alphabetically first category as the 0 level."
  },
  {
    "objectID": "class_02.html#regression-model-1",
    "href": "class_02.html#regression-model-1",
    "title": "Data Science for Business Applications",
    "section": "Regression model",
    "text": "Regression model\n\n# Remove scientific notation \noptions(scipen = 999)\n\n# Regression Model\nlm1 = lm(price ~ mileage + luxury, data = cars_luxury)\nsummary(lm1)\n\n\nCall:\nlm(formula = price ~ mileage + luxury, data = cars_luxury)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-24018  -6204  -1919   3727  78453 \n\nCoefficients:\n                Estimate   Std. Error t value            Pr(&gt;|t|)    \n(Intercept) 25422.756210   508.681485   49.98 &lt;0.0000000000000002 ***\nmileage        -0.185784     0.008688  -21.39 &lt;0.0000000000000002 ***\nluxuryyes   12986.388662   569.304402   22.81 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11010 on 2085 degrees of freedom\nMultiple R-squared:  0.3439,    Adjusted R-squared:  0.3433 \nF-statistic: 546.4 on 2 and 2085 DF,  p-value: &lt; 0.00000000000000022\n\n\n\nHow can we interpret these numbers?"
  },
  {
    "objectID": "class_02.html#interpretation-of-the-model",
    "href": "class_02.html#interpretation-of-the-model",
    "title": "Data Science for Business Applications",
    "section": "Interpretation of the model",
    "text": "Interpretation of the model\n\n\nEstimated model:\n\n\n\\[\n\\texttt{price} = 25,423 - 0.19\\times \\texttt{mileage} + 12,986 \\times \\texttt{luxury}\n\\]\n\nHow can we interpret the coefficients?\nintercept: For a car with zero mileage and luxury = \\(\\texttt{\"no\"}\\) = 0, the average selling price is equal to US$ 25,423.\nmileage: For a fixed type of car, for each extra increase in mileage (in miles), there will be a decrease of US$ 0.19 in the price of the car.\nluxury: For cars with the same mileage, the added price of being a luxury car (luxury = \\(\\texttt{\"yes\"}\\) = 1) is US$ 12,986.\nImportant: When we add a categorical variable to the regression model, the intercept is also referred to as the baseline. The effect of the categorical variable is also known as the offset."
  },
  {
    "objectID": "class_02.html#interpretation-of-the-model-1",
    "href": "class_02.html#interpretation-of-the-model-1",
    "title": "Data Science for Business Applications",
    "section": "Interpretation of the model",
    "text": "Interpretation of the model\n\nBy adding a categorical variable, we can also interpret this as different regression models depending on the number of groups.\nTo do so we add the effect of the categorical variable to the intercept.\nluxury = \\(\\texttt{\"yes\"}\\) = 1 \\[\n\\begin{align}\n\\texttt{price} &= 25,423 - 0.19\\times \\texttt{mileage} + 12,986 \\times (1) \\\\\n             &= (25,423 + 12,986) - 0.19\\times \\texttt{mileage} \\\\\n             &= 38,409 - 0.19\\times \\texttt{mileage} \\\\\n\\end{align}\n\\]\nluxury = \\(\\texttt{\"no\"}\\) = 0 \\[\n\\begin{align}\n\\texttt{price} &= 25,423 - 0.19\\times \\texttt{mileage} + 12,986 \\times (0) \\\\\n             &= 25,423 - 0.19\\times \\texttt{mileage} \\\\\n\\end{align}\n\\]"
  },
  {
    "objectID": "class_02.html#section",
    "href": "class_02.html#section",
    "title": "Data Science for Business Applications",
    "section": "",
    "text": "We can even visualize these two models in a plot\n\n\n    ggplot(cars_luxury, aes(x = mileage, y = price, col = luxury)) +\n      geom_point() + \n      geom_line(aes(y=predict(lm1)))"
  },
  {
    "objectID": "class_02.html#significance-and-predictions",
    "href": "class_02.html#significance-and-predictions",
    "title": "Data Science for Business Applications",
    "section": "Significance and Predictions",
    "text": "Significance and Predictions\n\nIs the price of a luxury cars statistically different of a non-luxury car?\n\n\nconfint(lm1)\n\n                    2.5 %        97.5 %\n(Intercept) 24425.1797220 26420.3326977\nmileage        -0.2028214    -0.1687463\nluxuryyes   11869.9244244 14102.8528996\n\n\n\nYes, with 95% confidence we can conclude that the price of a luxury car is different from a non luxury one.\nWhat is estimated price of luxury vehicle that has as mileage of 50000.\n\n\npredict(lm1, list(mileage = 50000, luxury = \"yes\"))\n\n       1 \n29119.95 \n\n\n\nThe estimated price of a 50,000-mile luxury car will be US$ 29,120."
  },
  {
    "objectID": "class_02.html#more-than-two-groups",
    "href": "class_02.html#more-than-two-groups",
    "title": "Data Science for Business Applications",
    "section": "More than two groups",
    "text": "More than two groups\n\nSuppose, instead of controlling the fact that a car is a luxury car or not, we want to observe the effect of badge on price.\nThe variable badge contains for groups or levels: “\\(\\texttt{Good Deal}\\)”, “\\(\\texttt{Great Deal}\\)”, “\\(\\texttt{No Badge}\\)” or “\\(\\texttt{Fair Price}\\)”.\nIs there a difference in the price of the car depending on what type of badge it holds?"
  },
  {
    "objectID": "class_02.html#section-1",
    "href": "class_02.html#section-1",
    "title": "Data Science for Business Applications",
    "section": "",
    "text": "Let’s plot the relation between mileage, price and badge\n\n\nggplot(cars_luxury, aes(x = mileage, y = price, col = badge)) +\n  geom_point()"
  },
  {
    "objectID": "class_02.html#regressions-model",
    "href": "class_02.html#regressions-model",
    "title": "Data Science for Business Applications",
    "section": "Regressions model",
    "text": "Regressions model\n\n\nRun the model: \\(\\texttt{price} = \\beta_0 + \\beta_1\\times \\texttt{mileage} + \\beta_2 \\times \\texttt{badge} + e\\)\n\n\nlm2 = lm(price ~ mileage + badge, data = cars_luxury)\nsummary(lm2)\n\n\nCall:\nlm(formula = price ~ mileage + badge, data = cars_luxury)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-19961  -6981  -2395   3629  82508 \n\nCoefficients:\n                    Estimate   Std. Error t value             Pr(&gt;|t|)    \n(Intercept)     35931.481715  1140.032009  31.518 &lt; 0.0000000000000002 ***\nmileage            -0.209568     0.009527 -21.997 &lt; 0.0000000000000002 ***\nbadgeGood Deal  -3556.561624  1057.385699  -3.364             0.000783 ***\nbadgeGreat Deal -8988.415770  1062.334934  -8.461 &lt; 0.0000000000000002 ***\nbadgeNo Badge   -9930.896296  1143.713386  -8.683 &lt; 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11860 on 2083 degrees of freedom\nMultiple R-squared:  0.2388,    Adjusted R-squared:  0.2374 \nF-statistic: 163.4 on 4 and 2083 DF,  p-value: &lt; 0.00000000000000022"
  },
  {
    "objectID": "class_02.html#interpretation-of-the-model-2",
    "href": "class_02.html#interpretation-of-the-model-2",
    "title": "Data Science for Business Applications",
    "section": "Interpretation of the model",
    "text": "Interpretation of the model\n\n\n\n\nintercept (baseline): For a car with zero mileage and with a fair price badge, the average selling price is equal to US$ 35,932 (\\(\\texttt{Good Deal} = 0\\),\\(\\texttt{Great Deal} = 0\\), \\(\\texttt{No Badge} = 0\\)).\nmileage: For a car with a fixed badge, for each extra increase in mileage (in miles), there will be a decrease of US$ 0.21 in the price of the car.\n\\(\\texttt{Good Deal} = 1\\), remainig levels equal to zero: For cars with the same mileage, there will be a decrease in their price if they have a good deal badge of US$ 3,557 compared to the baseline, that is, cars with a fair price badge.\n\\(\\texttt{Great Deal}  = 1\\), remainig levels equal to zero: For cars with the same mileage, there will be a decrease in their price if they have a great deal badge of US$ 8,988 compared to the baseline, that is, cars with a fair price badge.\n\\(\\texttt{No Badge}  = 1\\), remainig levels equal to zero: For cars with the same mileage, there will be a decrease in their price if they have no badge of US$ 8,988 compared to the baseline, that is, cars with a fair price badge."
  },
  {
    "objectID": "class_02.html#section-2",
    "href": "class_02.html#section-2",
    "title": "Data Science for Business Applications",
    "section": "",
    "text": "We have now 4 different models, one for each badge catgory.\nWe have four different intecepts."
  },
  {
    "objectID": "class_02.html#interactions",
    "href": "class_02.html#interactions",
    "title": "Data Science for Business Applications",
    "section": "Interactions",
    "text": "Interactions\n\nWe observed that there was a significant difference between the price of luxury and non-luxury cars.\nIs there a difference in the price of the car depending on what type of badge it holds?\nIn other words, does the effect of one variable (i.e., its slope coefficient) depend on the value of another?\nFor this we will include a interaction."
  },
  {
    "objectID": "class_02.html#interactions-1",
    "href": "class_02.html#interactions-1",
    "title": "Data Science for Business Applications",
    "section": "Interactions",
    "text": "Interactions\n\nThe idea is to add a term that is the product of the two variables:\n\n\\[\n\\texttt{price} = \\beta_0 + \\beta_1\\texttt{mileage} + \\beta_2\\texttt{luxury} + \\beta_3 (\\texttt{luxury} \\times \\texttt{mileage}) + e\n\\]\n\nIf we have a non-luxury car, then luxury = \\(\\texttt{\"no\"} = 0\\), so the \\(\\beta_2\\) and \\(\\beta_3\\) terms cancel out: \\[\n\\texttt{price} = \\beta_0 + \\beta_1\\texttt{mileage} + e\n\\]\nIf we have a luxury car, then luxury = \\(\\texttt{\"yes\"}  = 1\\), so we get both a different intercept and a different slope for mileage: \\[\n\\texttt{price} = (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3) \\texttt{mileage} + e\n\\]"
  },
  {
    "objectID": "class_02.html#regression-model-2",
    "href": "class_02.html#regression-model-2",
    "title": "Data Science for Business Applications",
    "section": "Regression Model",
    "text": "Regression Model\n\n\nLet’s run the regression model\n\n\nlm3 = lm(price ~ mileage*luxury, data = cars_luxury)\nsummary(lm3)\n\n\nCall:\nlm(formula = price ~ mileage * luxury, data = cars_luxury)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-25662  -6055  -2066   3563  83626 \n\nCoefficients:\n                      Estimate   Std. Error t value             Pr(&gt;|t|)    \n(Intercept)       23893.601384   545.040269  43.838 &lt; 0.0000000000000002 ***\nmileage              -0.154697     0.009595 -16.122 &lt; 0.0000000000000002 ***\nluxuryyes         19772.433662  1092.529243  18.098 &lt; 0.0000000000000002 ***\nmileage:luxuryyes    -0.155457     0.021457  -7.245    0.000000000000606 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10880 on 2084 degrees of freedom\nMultiple R-squared:   0.36, Adjusted R-squared:  0.3591 \nF-statistic: 390.8 on 3 and 2084 DF,  p-value: &lt; 0.00000000000000022"
  },
  {
    "objectID": "class_02.html#interpretation-of-the-model-3",
    "href": "class_02.html#interpretation-of-the-model-3",
    "title": "Data Science for Business Applications",
    "section": "Interpretation of the model",
    "text": "Interpretation of the model\n\nHow do we interpret this model?\nintercept (baseline), luxury = \\(\\texttt{\"no\"}\\) = 0: For a non-luxury car with zero mileage, the average selling price is equal to US$ 23,894.\nNow we have two cases:\nluxury = \\(\\texttt{\"no\"}\\) = 0:\nmileage: For each extra increase in mileage (in miles), there will be a decrease of US$ 0.15 in the price of non-luxury cars.\nluxury = \\(\\texttt{\"yes\"}\\) = 1:\nmileage: For each extra increase in mileage (in miles), there will be a decrease of US$ 0.16 in the price of luxury cars on top of the decrease of US$ 0.15 of non-luxury cars."
  },
  {
    "objectID": "class_02.html#interpretation-of-the-model-4",
    "href": "class_02.html#interpretation-of-the-model-4",
    "title": "Data Science for Business Applications",
    "section": "Interpretation of the model",
    "text": "Interpretation of the model\n\nWe also have the following interpretation:\nluxury = \\(\\texttt{\"yes\"}\\) = 0 \\[\n\\begin{align}\n\\texttt{price} &= 23,894 - 0.15\\times \\texttt{mileage} + 19,772 (0) - 0.16\\times \\texttt{mileage} (0) \\\\\n             &=  23,894 - 0.15\\times \\texttt{mileage}\n\\end{align}\n\\]\nluxury = \\(\\texttt{\"yes\"}\\) = 1 \\[\n\\begin{align}\n\\texttt{price} &= 23,894 - 0.15\\times \\texttt{mileage} + 19,772 (1) - 0.16\\times \\texttt{mileage} (1) \\\\\n             &=  (23,894 + 19,772) - (0.15 + 0.16) \\times \\texttt{mileage} \\\\\n             &=  43,666 - 0.31 \\times \\texttt{mileage} \\\\\n\\end{align}\n\\]\nWe have that not only the intercept change but also the slope."
  },
  {
    "objectID": "class_02.html#section-3",
    "href": "class_02.html#section-3",
    "title": "Data Science for Business Applications",
    "section": "",
    "text": "The lines are not parallel in this case which indicates a change in the slope due to the intercation term.\n\n\n\n    ggplot(cars_luxury, aes(x = mileage, y = price, col = luxury)) +\n      geom_point() + \n      geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "class_02.html#significance-and-predictions-1",
    "href": "class_02.html#significance-and-predictions-1",
    "title": "Data Science for Business Applications",
    "section": "Significance and Predictions",
    "text": "Significance and Predictions\n\nDo luxury cars depreciate faster than non-luxury cars?\n\n\nconfint(lm3)\n\n                          2.5 %        97.5 %\n(Intercept)       22824.7212986 24962.4814687\nmileage              -0.1735141    -0.1358795\nluxuryyes         17629.8713295 21914.9959940\nmileage:luxuryyes    -0.1975365    -0.1133770\n\n\n\nYes, with 95% confidence we can conclude that the price of a luxury car depreciates faster than a non-luxury one.\nWhat is estimated price of luxury vehicle that has as mileage of 50000.\n\n\npredict(lm3, list(mileage = 50000, luxury = \"yes\"))\n\n       1 \n28158.36 \n\n\n\nThe estimated price of a 50,000-mile luxury car will be US$ 28,158.\nThere was also a decrese in the RSE of this model compared to the model without the interaction. From \\(\\texttt{11860}\\) to \\(\\texttt{10,880}\\)."
  },
  {
    "objectID": "class_02.html#conlusion",
    "href": "class_02.html#conlusion",
    "title": "Data Science for Business Applications",
    "section": "Conlusion",
    "text": "Conlusion\n\nInteractions make a model more complex to analyze and explain, so it’s only worth doing so when you get better interpretation and more accurate predictions.\nWe can have interactions between different kinds of variables. Between categorical variables, numerical and categorical and, numerical and numerical.\nChoose interactions by thinking about what you are trying to model: if you suspect that the impact of one variable depends on the value of another, try an interaction term between them"
  },
  {
    "objectID": "class_03.html",
    "href": "class_03.html",
    "title": "Data Science for Business Applications",
    "section": "",
    "text": "Linear models are useful:\n\nPrediction - given a new observations\nExplanatory power - which variables affects the response\n\nBut issues in linear model are not uncommon:\n\nThey can affect the explanatory, and predictive power of our model\nThey can affect our confidence in our model\nWe will look at some of the most common problems in linear regression, and how we can fix them"
  },
  {
    "objectID": "class_03.html#regression-assumptions-and-potential-problems",
    "href": "class_03.html#regression-assumptions-and-potential-problems",
    "title": "Data Science for Business Applications",
    "section": "Regression Assumptions, and Potential Problems",
    "text": "Regression Assumptions, and Potential Problems\nLinear models are useful:\n\nPrediction - given a new observations\nExplanatory power - which variables affects the response\n\nBut issues in linear model are not uncommon:\n\nThey can affect the explanatory, and predictive power of our model\nThey can affect our confidence in our model\nWe will look at some of the most common problems in linear regression, and how we can fix them"
  },
  {
    "objectID": "class_03.html#regression-assumptions-and-potential-problems-1",
    "href": "class_03.html#regression-assumptions-and-potential-problems-1",
    "title": "Data Science for Business Applications",
    "section": "Regression Assumptions, and Potential Problems",
    "text": "Regression Assumptions, and Potential Problems\nThese issues are related to:\n\nRegression model assumptions\nInfluential observations, and outliers"
  },
  {
    "objectID": "class_03.html#multiple-regression-assumptions",
    "href": "class_03.html#multiple-regression-assumptions",
    "title": "Data Science for Business Applications",
    "section": "Multiple regression assumptions",
    "text": "Multiple regression assumptions\nWe need four things to be true for regression to work properly:\n\nLinearity: \\(Y\\) is a linear function of the \\(X\\)’s (except for the prediction errors).\nIndependence: The prediction errors are independent.\nNormality: The prediction errors are normally distributed.\nEqual Variance: The variance of \\(Y\\) is the same for any value of \\(X\\) (“homoscedasticity”)."
  },
  {
    "objectID": "class_03.html#non-linearity",
    "href": "class_03.html#non-linearity",
    "title": "Data Science for Business Applications",
    "section": "Non-Linearity",
    "text": "Non-Linearity\n\n\nWhat we would expect to observe in a regression where there is a linear relation?\n\n\n\nlibrary(tidyverse)\nggplot(linear_data, aes(x=X, y=Y)) +\n  geom_point() +\n  geom_smooth(method=\"lm\", se = FALSE)"
  },
  {
    "objectID": "class_03.html#residuals",
    "href": "class_03.html#residuals",
    "title": "Data Science for Business Applications",
    "section": "Residuals",
    "text": "Residuals\n\nLet’s plot the residuals \\(r_i\\), such that \\[r_i = y_i − \\widehat{y}_i\\] where \\(\\widehat{y}_i = \\widehat{\\beta}_0 + \\widehat{\\beta}_1 x_i\\) vs \\(x_i\\)\nHopefully identify non-linear relationships\nWe are looking for patterns or trends in the residuals"
  },
  {
    "objectID": "class_03.html#residuals-1",
    "href": "class_03.html#residuals-1",
    "title": "Data Science for Business Applications",
    "section": "Residuals",
    "text": "Residuals\n\n\nPlot of the residuals\nHow can these residuals be useful for us?"
  },
  {
    "objectID": "class_03.html#regression-diagnostic-plots",
    "href": "class_03.html#regression-diagnostic-plots",
    "title": "Data Science for Business Applications",
    "section": "Regression diagnostic plots",
    "text": "Regression diagnostic plots\nWe’ll use regression diagnostic plots to help us evaluate some of the assumptions.\nThe residuals vs fitted graph plots:\n\nResiduals on the \\(Y\\)-axis\nFitted values (predicted \\(Y\\) values) on the \\(X\\)-axis\n\nThis graph effectively subtracts out the linear trend between \\(Y\\) and the \\(X\\)’s, so we want to see no trend left in this graph."
  },
  {
    "objectID": "class_03.html#regression-diagnostic-plot",
    "href": "class_03.html#regression-diagnostic-plot",
    "title": "Data Science for Business Applications",
    "section": "Regression diagnostic plot",
    "text": "Regression diagnostic plot\n\n\nTo check non-linearity we focus on the Residual vs. Fitted plot\n\n\n\nlibrary(ggfortify)\n\nlm1 = lm(Y ~ X, data = linear_data)\nautoplot(lm1)"
  },
  {
    "objectID": "class_03.html#regression-diagnostic-plot-1",
    "href": "class_03.html#regression-diagnostic-plot-1",
    "title": "Data Science for Business Applications",
    "section": "Regression diagnostic plot",
    "text": "Regression diagnostic plot\n\nFrom the Residual vs. Fitted plot, we can observe that since the residuals are evenly distributed around zero in relation to the fitted values, we have that the linear regression model is a good fit for this data.\nThis means that we are learning the linear representation contained in this data."
  },
  {
    "objectID": "class_03.html#non-linearity-example",
    "href": "class_03.html#non-linearity-example",
    "title": "Data Science for Business Applications",
    "section": "Non-Linearity Example",
    "text": "Non-Linearity Example\n\n\nWhat we would expect to observe if the relation is non linear?\n\n\n\nggplot(nonlinear_data, aes(x = X, y = Y)) +\n  geom_point() +\n  geom_smooth(method=\"lm\", se = FALSE)"
  },
  {
    "objectID": "class_03.html#non-linearity-example-1",
    "href": "class_03.html#non-linearity-example-1",
    "title": "Data Science for Business Applications",
    "section": "Non-Linearity Example",
    "text": "Non-Linearity Example\n\nLet’s look at the residuals for this model\n\n\n\nLet’s check the residual plot"
  },
  {
    "objectID": "class_03.html#non-linearity-example-2",
    "href": "class_03.html#non-linearity-example-2",
    "title": "Data Science for Business Applications",
    "section": "Non-Linearity Example",
    "text": "Non-Linearity Example\n\nlm2 = lm(Y ~ X, data = nonlinear_data)\nautoplot(lm2)"
  },
  {
    "objectID": "class_03.html#non-linearity-example-3",
    "href": "class_03.html#non-linearity-example-3",
    "title": "Data Science for Business Applications",
    "section": "Non-Linearity Example",
    "text": "Non-Linearity Example\n\nFrom the Residual vs. Fitted, we can observe that the residuals are not evenly distributed around zero.\nThis indicates that for lower and higher values of \\(x_i\\) our model is overpredicting and underpredicting in the mid values.\nWhat are the implications in this case?\nWorse predictions"
  },
  {
    "objectID": "class_03.html#independence",
    "href": "class_03.html#independence",
    "title": "Data Science for Business Applications",
    "section": "Independence",
    "text": "Independence\n\nIndependence means that knowing the prediction error for one observation doesn’t tell you anything about the error for another observation\nData collected over time are usually not independent\nWe can’t use regression diagnostics to decide the independence\nWe have to measure the autocorrelation of the residuals\nWe’ll get back to autocorrelation when we discuss Time Series models"
  },
  {
    "objectID": "class_03.html#normality-assumption",
    "href": "class_03.html#normality-assumption",
    "title": "Data Science for Business Applications",
    "section": "Normality assumption",
    "text": "Normality assumption\n\nWhen we’ve been interpreting residual standard error (RSE) , we’ve used the following interpretation:\n95% of our predictions will be accurate to within plus or minus \\(2\\times RSE\\).\nIn order for this to be true, the residuals have to be Normally distributed"
  },
  {
    "objectID": "class_03.html#normality-example",
    "href": "class_03.html#normality-example",
    "title": "Data Science for Business Applications",
    "section": "Normality example",
    "text": "Normality example\n\n\nWe can check the distribution of the residuals\n\n\n\nlinear_data = linear_data %&gt;% \n  mutate(resid = residuals(lm1))\n\nggplot(linear_data, aes(x = resid)) + \n  geom_histogram(color = \"grey\", binwidth = 0.2)"
  },
  {
    "objectID": "class_03.html#normality-example-1",
    "href": "class_03.html#normality-example-1",
    "title": "Data Science for Business Applications",
    "section": "Normality example",
    "text": "Normality example\n\nBut how can we judge if the residuals follows a Normal distribution?\nThe key is to look at the Normal Q-Q plot, which compares the distribution of our residuals to a perfect Normal distribution.\nIf the dots line up along an (approximately) straight line, then the Normality assumption is satisfied."
  },
  {
    "objectID": "class_03.html#regression-diagnostic-plot-2",
    "href": "class_03.html#regression-diagnostic-plot-2",
    "title": "Data Science for Business Applications",
    "section": "Regression diagnostic plot",
    "text": "Regression diagnostic plot\n\n\nTo check for Normality we focus on the Normal Q-Q plot\n\n\n\nlm1 = lm(Y ~ X, data = linear_data)\nautoplot(lm1)\n\n\n\nIn this case the normality assumptions seem to be met"
  },
  {
    "objectID": "class_03.html#normality-example-2",
    "href": "class_03.html#normality-example-2",
    "title": "Data Science for Business Applications",
    "section": "Normality example",
    "text": "Normality example\n\nLet’s look at different data.\nIn this case the data has non Normal errors."
  },
  {
    "objectID": "class_03.html#normality-example-3",
    "href": "class_03.html#normality-example-3",
    "title": "Data Science for Business Applications",
    "section": "Normality example",
    "text": "Normality example\n\n\nHistogram of the residuals (right skewed)\n\n\n\nlm3 = lm(Y ~ X, data = non_normal)\n\nnon_normal = non_normal %&gt;% \n  mutate(resid = residuals(lm3))\n\nggplot(non_normal, aes(x = resid)) + \n  geom_histogram(color = \"grey\", binwidth = 1)"
  },
  {
    "objectID": "class_03.html#regression-diagnostic-plot-3",
    "href": "class_03.html#regression-diagnostic-plot-3",
    "title": "Data Science for Business Applications",
    "section": "Regression diagnostic plot",
    "text": "Regression diagnostic plot\n\nautoplot(lm3)"
  },
  {
    "objectID": "class_03.html#interpretation-of-the-plot",
    "href": "class_03.html#interpretation-of-the-plot",
    "title": "Data Science for Business Applications",
    "section": "Interpretation of the plot",
    "text": "Interpretation of the plot\n\nFrom the Normal Q-Q plot, we can observe that the residuals are not following the line that indicates the Normal quantiles\nThis means that our model results in non-normal residuals\nThis affects statistical tests, and confidence intervals"
  },
  {
    "objectID": "class_03.html#equal-variance",
    "href": "class_03.html#equal-variance",
    "title": "Data Science for Business Applications",
    "section": "Equal variance",
    "text": "Equal variance\n\nEqual variance is also known as “homoscedasticity”\nThe variance of \\(Y\\) should be about the same at any \\(X\\) value (or combination of values for the \\(X\\)’s).\nIn other words, the vertical spread of the points should be the same anywhere along the \\(X\\)-axis.\nIf there’s no equal variance then we might have heteroskedasticity.\nLower precision, estimates are further from the correct population value."
  },
  {
    "objectID": "class_03.html#equal-variance-example",
    "href": "class_03.html#equal-variance-example",
    "title": "Data Science for Business Applications",
    "section": "Equal variance example",
    "text": "Equal variance example\n\nThe vertical spread of the points is larger along the right side of the graph\n\n\nggplot(heter_data, aes(x = X, y = Y)) +\n  geom_point() +\n  geom_smooth(method=\"lm\", se = FALSE)"
  },
  {
    "objectID": "class_03.html#regression-diagnostic-plot-4",
    "href": "class_03.html#regression-diagnostic-plot-4",
    "title": "Data Science for Business Applications",
    "section": "Regression diagnostic plot",
    "text": "Regression diagnostic plot\n\n\nTo check for homoscidacity we focus on the Scale-Location plot\n\n\n\nlm4 = lm(Y ~ X, data = heter_data)\nautoplot(lm4)"
  },
  {
    "objectID": "class_03.html#interpretation-of-the-plot-1",
    "href": "class_03.html#interpretation-of-the-plot-1",
    "title": "Data Science for Business Applications",
    "section": "Interpretation of the plot",
    "text": "Interpretation of the plot\n\nFrom the Sacle-Location plot, we can observe that the residuals have a fan shape, indicating that there is heteroscedacity in the data.\nThis resulted in lower precision; thus, estimates are further from the correct population value."
  },
  {
    "objectID": "class_03.html#influential-observations",
    "href": "class_03.html#influential-observations",
    "title": "Data Science for Business Applications",
    "section": "Influential observations",
    "text": "Influential observations\n\nAdding a new observation with \\(X\\) near the mean of \\(X\\) doesn’t matter much even if it’s out of line with the rest of the data:\n\n\n\nThis point has high residual but low leverage. RSE = 0.5504"
  },
  {
    "objectID": "class_03.html#diagnostics-plot",
    "href": "class_03.html#diagnostics-plot",
    "title": "Data Science for Business Applications",
    "section": "Diagnostics Plot",
    "text": "Diagnostics Plot\n\nWe can observe the point with high residual on the Residual vs. Leverage plot\n\n\nlm5 = lm(Y ~ X, data = outlier_residual)\nautoplot(lm5)"
  },
  {
    "objectID": "class_03.html#high-leverage",
    "href": "class_03.html#high-leverage",
    "title": "Data Science for Business Applications",
    "section": "High leverage",
    "text": "High leverage\n\nWe can also have points with high leverage - when a point in \\(X\\) is distant from the average on \\(X\\)\n\n\n\nThis point has low residual but high leverage. RSE = 0.2956"
  },
  {
    "objectID": "class_03.html#high-leverage-1",
    "href": "class_03.html#high-leverage-1",
    "title": "Data Science for Business Applications",
    "section": "High leverage",
    "text": "High leverage\n\nWe can observe the point with high leverage on the Residual vs. Leverage plot\n\n\nlm6 = lm(Y ~ X, data = outlier_leverage)\nautoplot(lm6)"
  },
  {
    "objectID": "class_03.html#points-with-high-influence",
    "href": "class_03.html#points-with-high-influence",
    "title": "Data Science for Business Applications",
    "section": "Points with high influence",
    "text": "Points with high influence\n\nPoints with high leverage and high residuals are known as influential points\n\n\n\nThis point has high residual but high leverage. RSE = 0.8281"
  },
  {
    "objectID": "class_03.html#points-with-high-influence-1",
    "href": "class_03.html#points-with-high-influence-1",
    "title": "Data Science for Business Applications",
    "section": "Points with high influence",
    "text": "Points with high influence\n\nWe can observe the point with high influence on the Residual vs. Leverage plot\n\n\nlm7 = lm(Y ~ X, data = outlier_influence)\nautoplot(lm7)"
  },
  {
    "objectID": "class_03.html#points-with-high-influence-2",
    "href": "class_03.html#points-with-high-influence-2",
    "title": "Data Science for Business Applications",
    "section": "Points with high influence",
    "text": "Points with high influence\n\nWhen a case has a very unusual \\(X\\) value, it has leverage — the potential to have a big impact on the regression line\nIf the case is in line with the overall trend of the regression line, it won’t be a problem\nBut when that case also has a Y (high residual) value that is out of line\nWe need both a large residual and high leverage for an observation to be influential\nWe should be worried about these points\nThey affect the coefficents and predictions"
  }
]